{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22122568",
   "metadata": {},
   "source": [
    "# FrameNet Processing and GPT-2 Training\n",
    "This notebook guides through processing FrameNet data and training a GPT-2 model based on the data.\n",
    "We programmatically execute the scripts: `process_framenet.py`, `load_and_process_framenet.py`, and `train_gpt2.py`.\n",
    "Each script is explained before execution.\n",
    "Ensure all dependencies are installed before executing this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a5064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers numpy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89153e9",
   "metadata": {},
   "source": [
    "# Processing FrameNet Xml Data\n",
    "The `process_framenet.py` script parses FrameNet xml data and processes it into a Python pickle object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8370428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python process_framenet.py --input /path/to/input --output /path/to/output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb4b0bf",
   "metadata": {},
   "source": [
    "# Loading And Processing FrameNet Data\n",
    "The `load_and_process_framenet.py` script loads the FrameNet data from the created pickle file and processes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1f9ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python load_and_process_framenet.py --input /path/to/input --output /path/to/output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6236e30",
   "metadata": {},
   "source": [
    "# Training GPT-2 Model\n",
    "The `train_gpt2.py` script uses the processed FrameNet data to train a GPT-2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd2e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_gpt2.py --input /path/to/input --output /path/to/output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a312f",
   "metadata": {},
   "source": [
    "# Final Thoughts\n",
    "This notebook provided a procedural execution of FrameNet processing and GPT-2 training.\n",
    "It is important to adjust the input and output file paths based on your setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371e3bc3",
   "metadata": {},
   "source": [
    "# References\n",
    "- [FrameNet](https://framenet.icsi.berkeley.edu/fndrupal/)\n",
    "- [Hugging Face Transformers](https://huggingface.co/transformers/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3582b5d0",
   "metadata": {},
   "source": [
    "# README\n",
    "# FrameNet Fine-Tuning for GPT-2\n",
    "\n",
    "This repository contains scripts for fine-tuning the GPT-2 model on FrameNet data.\n",
    "\n",
    "## Description\n",
    "\n",
    "The scripts provided in this project are designed to preprocess FrameNet data and fine-tune a GPT-2 model using this data. The main goal is to provide a starting point for training a GPT-2 model to generate text based on FrameNet linguistic frames.\n",
    "\n",
    "## Repository Structure\n",
    "\n",
    "- `processed_framenet_data.pkl`: This file contains the preprocessed FrameNet data.\n",
    "- `train_gpt2.py`: This Python script handles loading the processed data, preparing it for the GPT-2 model, and fine-tuning the GPT-2 model on the data.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "Before running the scripts, install the necessary Python libraries included in the `requirements.txt` file using pip:\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "## Usage\n",
    "\n",
    "To run the GPT-2 training script after installing the requirements, use the following command:\n",
    "\n",
    "```\n",
    "python train_gpt2.py\n",
    "```\n",
    "\n",
    "This will start the process of loading the data, tokenizing it, and fine-tuning the GPT-2 model on it. The fine-tuned model will be saved as `fine_tuned_gpt2.pt`.\n",
    "\n",
    "Please note that fine-tuning GPT-2 is a resource-intensive task that requires a machine with a good amount of computation power, ideally with a strong GPU.\n",
    "\n",
    "\n",
    "\n",
    "## Using GitHub Codespaces and VS Code Remote - Containers\n",
    "\n",
    "This repository includes a `.devcontainer` directory that specifies a Python development environment with necessary libraries and Jupyter notebook server, ideally for use with GitHub Codespaces or Visual Studio Code Remote - Containers extension.\n",
    "\n",
    "To set this up:\n",
    "\n",
    "1. Push the `.devcontainer` directory to your GitHub repository.\n",
    "2. Open the repository in a new GitHub Codespace by clicking the 'Code' button on your repository page, then 'Open with Codespaces' and 'New Codespace', or use the Remote - Containers extension in VS Code.\n",
    "3. Github will build the codespace using the Dockerfile in the `.devcontainer` directory. It should start a new session in your browser with VS Code running in the cloud, but with the code in your repository.\n",
    "\n",
    "With the provided Dockerfile, a Jupyter notebook server starts when the Docker container is run. To start it manually, run:\n",
    "\n",
    "```\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "Additionally, remember to rebuild the codespace whenever you make changes to the Dockerfile or devcontainer.json. You can do this through the Command Palette (F1 or CMD + Shift + P) by typing 'Rebuild Container'.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
